# Comments are provided throughout this file to help you get started.
# If you need more help, visit the Docker compose reference guide at
# https://docs.docker.com/compose/compose-file/

# Here the instructions define your application as a service called "server".
# This service is built from the Dockerfile in the current directory.
# You can add other services your application may depend on here, such as a
# database or a cache. For examples, see the Awesome Compose repository:
# https://github.com/docker/awesome-compose
---
version: '3.4'
services:
  api:
    env_file: .env
    command: poetry run uvicorn src.docqa_stream.server:app  --host  0.0.0.0 --port '${FASTAPI_PORT}'
    build:
      context: .
      dockerfile: Dockerfile
    container_name: fastapi-application
    depends_on:
      - weaviate
      - t2v-transformers
    ports:
      - '${FASTAPI_PORT}:${FASTAPI_PORT}'
    restart: "on-failure"
  weaviate:
    env_file: .env
    command:
      - --host
      - 0.0.0.0
      - --port
      - '${WEAVIATE_PORT}'
      - --scheme
      - http
    image: cr.weaviate.io/semitechnologies/weaviate:1.21.1
    ports:
      - '${WEAVIATE_PORT}:${WEAVIATE_PORT}'
    volumes:
      - weaviate_data:/var/lib/weaviate
    restart: "on-failure"
    environment:
      TRANSFORMERS_INFERENCE_API: 'http://t2v-transformers:8080'
      QUERY_DEFAULTS_LIMIT: 25
      AUTHENTICATION_ANONYMOUS_ACCESS_ENABLED: 'true'
      PERSISTENCE_DATA_PATH: '/var/lib/weaviate'
      DEFAULT_VECTORIZER_MODULE: 'text2vec-transformers'
      ENABLE_MODULES: 'text2vec-transformers'
      CLUSTER_HOSTNAME: 'node1'
  t2v-transformers:
    image: semitechnologies/transformers-inference:sentence-transformers-multi-qa-MiniLM-L6-cos-v1
    environment:
      ENABLE_CUDA: '0'
volumes:
  weaviate_data:
...